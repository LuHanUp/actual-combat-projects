# 分布式基础

## 微服务
将一个单独的应用程序开发为一套小服务，每个小服务运行在自己的进程中，并使用轻量级机制通信(通常是HTTP)
简而言之:**就是将一个大型的单体应用,根据业务边界进行服务拆分，分为不同的小服务独立部署运行**

## 集群、分布式、节点概念
集群是个物理形态，分布式是个工作方式。  
只要是一堆机器就可以叫做集群，它们是不是一起协作干活，这个谁也不知道

> 《分布式系统原理与规范》定义："分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像单个相关系统" 分布式熊是建立在网络之上的软件系统

分布式就是将不同的业务分布在不同的地方  
集群指的是将几台服务器集中在一起，实现同一业务

**分布式中的每一个节点，都可以做集群。而集群并不一定就是分布式的。**

节点:集群中的一个服务器

## 远程调用
在分布式系统中,各个服务可能处于不同的主机，但是服务之间不可避免的需要互相调用

> SpringCloud中使用HTTP+JSON的方式完成远程调用

## 负载均衡
分布式系统中，A服务需要调用B服务，B服务在多台机器中都存在，A调用任意一个服务器均可完成功能  
为了使得每一个服务器都不要太忙或者太闲，就可以使用负载均衡的调用每一个服务器，提升网站的健壮性

**常见的负载均衡算法如下**：
- 轮询：按照注册顺序依次请求，直到最后一个，然后重新从第一个开始循环
- 最小连接：优先选择连接数最少的，在会话较长的情况下可以考虑采取这种方式
- 散列：通过IP来散列到不同的服务器上

# SpringBoot
在WebMvcAutoConfiguration下
~~~java
// 处理HTTP PUT、DELETE等方法
@Bean
@ConditionalOnMissingBean(HiddenHttpMethodFilter.class)
@ConditionalOnProperty(prefix = "spring.mvc.hiddenmethod.filter", name = "enabled", matchIfMissing = false)
public OrderedHiddenHttpMethodFilter hiddenHttpMethodFilter() {
    return new OrderedHiddenHttpMethodFilter();
}
~~~

# 分布式事务

## 同一个对象内事务方法互调默认失效问题
解决方案：使用代理对象来解决即可
1. 引入`spring-boot-starter-aop`：主要是其引用了aspectj
2. 开启aspectj动态代理功能：`@EnableAspectJAutoProxy(exposeProxy=true)`
3. 用代理对象调用即可：`xxxService = AopContext.currentProxy();xxxService.事务方法()`

## 使用分布式事务之Seata中间件
> 使用`RAFT`算法保持分布式一致性：[raft](http://thesecretlivesofdata.com/raft/)

### AT模式-适用于一般的分布式事务的场景
1. 涉及到分布式事务的数据库中都要添加一个`undo_log`表
~~~sql
-- 注意此处0.7.0+ 增加字段 context
CREATE TABLE `undo_log` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `branch_id` bigint(20) NOT NULL,
  `xid` varchar(100) NOT NULL,
  `context` varchar(128) NOT NULL,
  `rollback_info` longblob NOT NULL,
  `log_status` int(11) NOT NULL,
  `log_created` datetime NOT NULL,
  `log_modified` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
~~~
2. 安装事务协调器TC
    1. registry-conf：修改为对应的注册中心相关配置
        ~~~conf
        registry {
          # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa
          type = "nacos"
        
          nacos {
            application = "seata-server"
            serverAddr = "192.168.2.142:8848"
            group = "SEATA_GROUP"
            namespace = ""
            cluster = "default"
            username = ""
            password = ""
          }
        }
        ~~~
3. 项目中整合seata
    1. 引入seata组件`spring-cloud-starter-alibaba-seata`,注意其中的版本(TC要安装对应的版本)
    2. 在需要分布式事务的方法上标记一个注解`@GlobalTransactional`即可
    3. **所有参与**分布式事务的微服务要使用seata里`DataSourceProxy`的代理项目的数据源
        ~~~java
        @Bean
        public DataSource dataSource(DataSourceProperties dataSourceProperties) {
            HikariDataSource hikariDataSource = dataSourceProperties
                           .initializeDataSourceBuilder()
                           .type(HikariDataSource.class)
                           .build();
            if (StringUtils.hasText(dataSourceProperties.getName())) {
                hikariDataSource.setPoolName(dataSourceProperties.getName());
            }
            return new DataSourceProxy(hikariDataSource);
        }
        ~~~
    4. 参与分布式事务的微服务需要引入`file.conf`和`registry.conf`文件到resources中
        1. 将`spring.cloud.alibaba.seata.tx-service-group=${spring.application.name}-fescar-service-group`
    5. 给参与分布式事务的每个小事务的方法添加注解`@Transactional`

# Feign丢失请求头问题
浏览器请求接口A的时候会自动带上请求头信息----->接口A,其中接口A会用Feign调用服务B的接口B------>因为Feign会重新创建一个新的request,所以
就不会带上任何的请求头信息而导致接口B获取请求头中的数据是获取不到的

解决方案：加上feign远程调用的拦截器
~~~java
@Bean
public RequestInterceptor requestInterceptor() {
    // 在使用Feign进行远程调用时,在Feign创建的新的request中追加上请求头信息
    RequestInterceptor appendHeader = (template) -> {
        ServletRequestAttributes requestAttributes = (ServletRequestAttributes) RequestContextHolder.currentRequestAttributes();
        HttpServletRequest request = requestAttributes.getRequest();
        Enumeration<String> headerNames = request.getHeaderNames();
        while (headerNames.hasMoreElements()) {
            String headerName = headerNames.nextElement();
            // 向Feign创建的request中追加header信息
            template.header(headerName, request.getHeader(headerName));
        }
    };
    return appendHeader;
}
~~~

# Spring Cache
- Spring从3.1定义了Cache和CacheManager接口来统一不同的缓存技术，
并且支持使用JCache(JSR-107)注解简化开发
- Cache接口为缓存的组件规范定义，包含缓存的各种操作集合
- 每次调用需要缓存功能的方法时，Spring会检查指定参数指定的目标方法是否已经被调用过(数据是否已经缓存过)
    - 如果有就会直接从缓存获取最后的结果
    - 如果没有就调用方法后将结果缓存起来
- 使用Spring缓存我们需要关注一下2点
    - 确定方法需要被缓存已经他们的缓存策略
    - 从缓存读取之前缓存存储的数据

Spring Cache最重要的四个注解：
- `@Cacheable`：触发将数据保存到缓存的操作
- `@CacheEvict`：触发将数据从缓存中删除的操作
- `@CachePut`：不影响方法执行更新操作
- `@Caching`：组合以上多个操作
- `@CacheConfig`：在类几倍共享缓存的相同配置

## @Cacheable
表示当前的方法需要被缓存，如果缓存中，那么不会再调用方法。如果缓存没有，那么会执行方法后将结果存入缓存
 
**默认行为**：
1. 如果缓存中有，那么不再调用方法
2. key默认生成的规则是：缓存的名字::SimpleKey []
3. 缓存的value的值：默认使用jdk序列化机制，将序列化后的数据存入缓存
4. 默认ttl时间-1

**自定义配置**：
1. 指定生成缓存时的key：使用@Cacheable的key属性，可以使用SpEL表达式,如果想设置为普通的字符串可以使用''
2. 指定缓存数据的过期时间：需要在配置文件中指定过期时间`spring.cache.redis.time-to-live=时间毫秒`
3. 指定缓存的序列化方式：`redisCacheConfiguration.serializeValuesWith`,参考如下配置
~~~java
@Bean
RedisCacheConfiguration redisCacheConfiguration() {
    RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig();
    // 将value的序列化方式修改为使用fastJson来进行序列化
    redisCacheConfiguration = redisCacheConfiguration.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(
        new GenericFastJsonRedisSerializer()
    ));
    return redisCacheConfiguration;
}
~~~

# Object类的划分

PO-persistant object  
持久化对象,一般指的就是数据表对应的entity

DO-domain object  
领域对象,就是从现实世界中抽象出来的有形或无形的业务实体

TO-transfer object  
传输对象，不同应用程序之间传输数据的对象

DTO-data transfer object  
数据传输对象，这个概念来源于j2EE的设计模型，原来的目的是为了EJB的分布式应用提供
粗粒度的数据实体，以减少分布式的调用次数，从而提高分布式调用的性能和降低网络负载
但在这里泛指展示层与服务层之间的数据传输对象

VO-value object/view object  
值对象/视图对象
1. 主要对应页面显示（web页面/swt、swing界面）的数据对象。
2. 接受页面传递数据的对象
3. 可以和表对应，也可以不，这根据业务的需要。

BO-business object 业务对象  
业务对象主要作用是把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象。  
比如一个简历，有教育经历、工作经历、社会关系等等。我们可以把教育经历对应一个PO，工作经历对应一个PO，社会关系对应一个PO。  
建立一个对应简历的BO对象处理简历，每个BO包含这些PO。  
这样处理业务逻辑时，我们就可以针对BO去处理。  
封装业务逻辑为一个对象（可以包括多个PO，通常需要将BO转化成PO，才能进行数据的持久化，反之，从DB中得到的PO，需要转化成BO才能在业务层使用）。

关于BO主要有三种概念
1. 只包含业务对象的属性；
2. 只包含业务方法；
3. 两者都包含。  
> 在实际使用中，认为哪一种概念正确并不重要，关键是实际应用中适合自己项目的需要。

# Vue

## 父子组件传递数据

1. 子组件给父组件传递数据,使用事件机制
    1. 子组件给父组件发送一个事件,在这个事件中携带数据
        this.$emit(事件名称,参数/数据...)
    2. 父组件中感知这个事件
        <子组件 @事件名称="该事件需要执行的方法" />
    3. 然后需要执行的方法跟平时vue绑定方法一样即可

# Elastic Search

## 基本概念
### Index索引
动词，相当于Mysql中的insert。  
名词，相当于MySQl中的Database

### Type类型
在Index中，可以定义一个或多个type，每个type类似于Mysql中的Table。每一种类型放在一起

### Document文档
保存在某个Index、某个type下的一条数据，document是JSON格式的

### 倒排索引
将数据拆分成一个一个的关键词，然后保存每个关键词在哪些数据中出现过，  
比如存储`红海行动`、`特别行动`，数据保存在xxIndex、xxType下，记录的id分别为1、2，
那么就会有一张表来存储对应关系，如下：  

|关键词|出现在哪些记录中|
|:---:|:---:|
|红海|1|
|行动|1,2|
|特别|2|

## 基本CRUD

### _cat
GET /_cat/nodes     查看所有的节点
GET /_cat/health    查看es健康状况
GET /_cat/master    查看主节点
GET /_cat/indices   查看所有的index,类似于Mysql中的show databases;

### 索引一个文档
保存一条数据在哪个索引哪个类型下，指定使用哪个唯一标识(POST方式可以不指定,如果不指定es会随机生成一个id)
PUT  /{{indexName}}/{{typeName}}/{{唯一标识}}
POST /{{indexName}}/{{typeName}}/\[{{唯一标识}}]
数据：{"name":"john Doe"}

**返回结果如下**：其中带_都是元数据
~~~text
{
    "_index": "index1", // 在哪个索引下
    "_type": "type1", // 在哪个文档下
    "_id": "1", // 唯一标识
    "_version": 1, // 数据的版本
    "result": "created", // 结果 created：新建 updated：修改
    "_shards": {    // 分片相关参数
        "total": 2,
        "successful": 1,
        "failed": 0
    }, 
    "_seq_no": 0,
    "_primary_term": 1
}
~~~

### 查询文档
GET /{{indexName}}/{{typeName}}/{{唯一标识}}

**返回的结果如下**：
~~~text
{
    "_index": "index1", 
    "_type": "type1",
    "_id": "1",
    "_version": 1,
    "_seq_no": 0, // 并发控制字段，每次更新就会+1，用来做乐观锁
    "_primary_term": 1, // 同上，主分片重新分配，如重启，就会发生变化
    "found": true, // 是否找到了
    "_source": {    // 真正之前保存的数据内容
        "name": "john Doe"
    }
}
~~~

### 修改文档
PUT  /{{indexName}}/{{typeName}}/{{唯一标识}}
POST /{{indexName}}/{{typeName}}/\[{{唯一标识}}]/_update
数据：{"name":"john Doe"}

POST会对比数据,如果和库里的数据不一致才会进行更新,否则不执行任何操作
PUT直接更新

### 删除
删除一条数据：
DELETE /{{indexName}}/{{typeName}}/{{唯一标识}}
删除索引
DELETE /{{indexName}}

### 批量操作
POST /{{indexName}}/{{typeName}}/_bulk
数据格式如下:一行为一个操作  
{action:{metadata}\n
{request body}\n

例如：保存了id为1内容为`{"name":"xxx"}` id为2内容为`{"name":"xxx222"}`的2条数据  
{"index":{"_id":"1"}}
{"name":"xxx"}
{"index":{"_id":"2"}}
{"name":"xxx222"}

## 数据检索
方式一：GET /{{indexName}}/_search\[参数]
方式二：
GET /{{indexName}}/_search
{
    ACTION_NAME:{
        argument:value
    }
}
或者
{
    ACTION_NAME:{
        field_name:value
    }
}
ACTION_NAME可以是query、size、from等等
其中argument可以是match、match_all等等
field_name就是属性名称
> 其中第二种方式称为Query DSL

## Query DSl

### match
如果数据值是数值类型,那么就是精确匹配,如果值是字符串类型,那么就是模糊匹配
检索的单词会进行分词

### match_phrase
短语匹配，将需要匹配的值当成一个整体单词进行检索，**并且这个单词不会进行分词**
> 和.keyword的区别：match_phrase是contains(关键词) 而.keyword是eq(关键词)

### multi_match
多字段匹配，可以指定在多个字段中匹配
```json
{
  "query": {
    "multi_match": {
      "query": "需要检索的关键词",
      "fields": ["字段1","字段2"]
    }
  }
}
```

### bool
复合查询，可以合并多个查询条件
```json
{
  "query": {
    "bool": {
      "must": [
        {}
      ],
      "must_not": [
        {}
      ],
      "should": [
        {}
      ],
      "filter": {}
    }
  }
}
```
must：必须满足这些条件
must_not：必须不满足这些条件
should：应该满足,可以不满足
filter：结果过滤，不会计算相关性得分

### term
适用于数值类型的检索

# 搭建域名访问
域名访问的流程如下:  
访问gulimall.com ---> 由host指向虚拟机的ip进行解析访问 ---> nginx拦截gulimal.com的访问转发到网关应用 ---> 网关在转发到各个微服务

## 1. 配置域名HOST映射
推荐使用SwitchHosts修改host文件
~~~~text
虚拟机的ip gulimall.com
~~~~

## 2. 配置nginx server块
使用负载均衡配置将其请求转发到网关应用
> 其中有个坑，nginx在转发时会丢失host域名，需要设置`proxy_set_header Host $host`不丢弃host请求头

1. 使用upstream块配置网关的地址，在http块中进行配置，一般建议写在server块上面
~~~text
    upstream gulimall{ # 其中gulimall为这个upstream的名称
      server 192.168.80.185:88; # 配置负载均衡到的服务器地址，其中192.168.80.185为网关服务的ip地址
    }
~~~
2. 在server块中配置请求拦截和转发
~~~text
    listen       80; # 监听的服务端口
    server_name  gulimall.com; # 表示监听域名为gulimall.com的请求

    #charset koi8-r;
    #access_log  /var/log/nginx/log/host.access.log  main;

    location / {
        proxy_set_header Host $host; # 代理时不丢失host请求头
        proxy_pass http://gulimall; # 代理到upstream上游服务器的配置组,其中gulimall为配置的upstream名称
    }
~~~

## 3. 网关服务配置路由
~~~yaml
        - id: gulimall-host_route # gulimal.com域名的路由规则
          uri: lb://xxxx服务 # 转发到的具体服务
          predicates:
            - Host=**.gulimall.com # **表示任意的子域名
~~~
> 注意：尽量将域名路由的规则放到最后，不然因为gateway是根据顺序来的，就会可能导致下面有一些可以命中的规则不会被命中

# 性能监控优化

## java对象创建分配内存流程
新对象的内存申请流程如下：
1. `Eden`区是否有足够的空间存放?，如果有空间那么就直接分配内存即可
2. 如果`Eden`区空间不够了，那么就会对新生代进行一次`YGC`(也称为`MinorGC`)
3. 经过YGC后：`YGC`会将`Eden`区没有被回收的对象存放入`Survival`区中
    1. `Eden`区放的下，直接分配内存
    2. `Eden`区还是放不下，那么就会尝试将对象存放入`Old区`
        1. 老年代是否放的下?
            1. 放到下就直接分配内存
            2. 如果放不下就对整个堆进行一次`Full GC`
            3. 再次尝试老年代是否放的下，如果放的下直接分配内存
            4. 如果还是放不下，那么就会抛出`OOM异常`

## 优化静态资源的访问
将静态资源都存放入nginx中进行访问
1. 在nginx的html文件夹中创建static文件夹
~~~shell
cd /mydata/nginx/html

mkdir static
~~~
2. 将项目的静态文件上传到static文件夹中
3. 删除项目中的静态资源
4. 修改nginx的配置,修改gulimall.conf添加如下内容
~~~text
    location /static{
        root   /usr/share/nginx/html;
    }
~~~

## 优化应用程序的堆空间大小
如果程序在频繁的进行YGC和Full GC就可以考虑调整程序的内存大小,如下参数进行调整：
~~~text
-Xmx1024m -Xms1024m -Xmn512
~~~
> -Xmn表示是年轻代空间的大小 -Xmx表示能够使用的最大内存 -Xms设置程序初始化时内存栈的大小

# OAuth2.0
OAuth是一个开放标准，允许用户授权第三方网站访问他们存储在另外的服务提供者上的信息
而不需要将用户名和密码提供给第三方网站或分享他们数据的所有内容

OAuth2.0对于用户习惯的OpenApi(例如:获取用户信息、动态同步、照片、日志、分享等)，
为了保护用户数据的安全和隐私，第三方网站访问用户数据都需要显式的向用户征求授权

**OAuth2.0流程**：
client(第三方应用,如CSDN)----向用户申请请求认证--->resource ouner(用户本人)-----用户授权(自己输入自己的社交账户)----> 
resource ouner-----使用上步的授权进行认证-------->Authorization Server(认证服务器,如：QQ服务器)------认证通过,返回令牌-------->
client-------使用令牌，获取受保护的信息------->Resource Server----认证令牌，返回受保护信息---->client

# 分布式下session共享问题

## 多个服务之间共享session
**~~1. session复制~~**  
通过已有的session将其复制/同步到别的服务中

优点：
- tomcat原生支持，只需要修改配置文件即可

缺点：
- session同步需要数据传输，占用大量网络带宽，降低了服务器集群的业务处理能力
- 任意一台web-server保存的数据都是所有web-server的session的总和，受到内存
限制无法水平扩展更多的web-server
- 大型分布式集群的情况下，由于所有web-server都全量保存数据，所以此方案不可取

**~~2. 客户端存储~~**  
将session信息存储在客户端中，每次请求服务端时将信息带上

优点：
- 服务器不需要存储session，用户保存自己的session信息项到cookie中，节省服务器资源

缺点：
- 每次请求都需要携带用户在cookie中的完整信息，浪费网络带宽
- session数据放在cookie中，由于cookie有长度限制(4K),不能保存大量信息
- session数据放在cookie中，存在泄漏，篡改、窃取等安全隐患

3. 统一存储  
将session数据统一的存储在一个位置，如：redis等，客户端只保存一个唯一的token
服务端通过token从redis中获取session信息

## 不同域名之间的session共享问题
设置session时指定域名为最大的父域名即可

# 单点登录
1. host配置
~~~shell script
127.0.0.1 sso.server.com
127.0.0.1 client1.com
127.0.0.1 client2.com
~~~

核心：三个系统即使域名不一样，想办法给三个系统同步同一个用户的票据
1. 认证服务器：sso.server.com
2. 其他系统，想要登录去认证服务器登录，登录成功跳转回来
3. 只要有一个登录，其他系统就不需要登录
4. 全系统唯一一个sessionid，所有系统可能域名都不相同

> 具体请查看test-sso-server、test-sso-client-1、test-sso-client-2三个演示项目
> 其中test-sso-server访问域名是：sso.server.com
> test-sso-client-1访问域名是：client1.com
> test-sso-client-2访问域名是：client2.com

# 消息中间件

## JSM和AMQP的对比
|                | JSM(Java Message Service)                                    | AMQP(Advanced Message Queuing Protocol)                      |
| :------------: | :----------------------------------------------------------- | :----------------------------------------------------------- |
|      定义      | Java api                                                     | 网络协议                                                     |
|     跨语言     | 否                                                           | 是                                                           |
|     Model      | 提供了两种消息模型:<br />1.Peer-2-Peer <br />2.Pub/sub       | 提供了五种消息模型<br />1.direct exchange<br />2.fanout exchange<br />3. Topic change<br />4. headers exchange<br />5. system exchange |
| 支持的消息类型 | 多种消息类型：<br />1. TextMessage<br />2. MapMessage<br />3. BytesMessage<br />4. StreamMessage<br />5. ObjectMessage<br />6. Message(只有消息头和属性) | byte[] 当实际应用时，有复杂的消息，可以将消息序列化后发送    |
|    综合评价    | JSM定义了Java api层面的标准，在java体系中，多个client均可以通过JMS进行交互，不需要应用修改代码，但是其对跨语言的支持较差 | AMQP定义了wire-level层的协议标准，天然具有跨语言特性         |

## RabbitMQ

### 基本概念

**Message**：消息，消息是不具名的，它有消息头和消息体组成。消息体是不透明的，
而消息头则由一系列的可选属性组成，这些属性包括routing-key、priority、delivery-mode等等

Publisher：消息的生产者，也是一个向交换器发布消息的客户端应用程序

**Exchange**：交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列
Exchange有4中类型：direct、fanout、topic、headers不同类型的Exchange转发消息的策略有所不同
- direct:直接类型交换器，**精确匹配路由键**，比如一个队列绑定的交换器的路由键为'dog'，则只会转发routing key为'dgg'的消息，
不会转发'dog.aaa'这类的消息
- fanout:广播模式，每个发到fanout类型的交换器的消息都会被分发到绑定的队列上去，**不关心路由键是什么**
- topic:发布订阅模式，**将路由键和某个模式进行匹配**，如果匹配了则会发到这个队列上，每个单词之间使用`.`隔开
它同样也会识别两通配符`#`、`*`。`#`匹配0个或多个单词、`*`匹配一个单词

**Queue**：消息队列，用来存储消息知道发送给消费者，它是消息的容器，也是消息的终点。
一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走

**Binding**：绑定，交换器和Queue的绑定关系。一个绑定就是就与路由键将交换器和消息队列连接起来的路由规则，
所以可以将交换器理解成一个由绑定构成的路由表。
Exchange和Queue的绑定可以是多对多的关系

**Channel**：信道，多路复用连接中的一条独立的双向数据流通道。
信道是建立在真实的TCP连接内的虚拟连接，AMQP命令都是通过信道发出去的，不管是发布消息，订阅队列还是接收消息，
这些动作都是通过信道完成的。因为对于操作系统来说建立和销毁TCP都是非常昂贵的开销，所以引入了信道的概念，用来复用一条TCP连接。

VHost：虚拟主机，相当于一个物理隔离，每个虚拟主机之间互不影响，相当于在一个RabbitMQ中装了多个RabbitMQ，使用路径来表示一个虚拟主机

### Docker安装RabbitMQ
~~~shell script
docker run -d --name rabbitmq --restart=always -p 5671:5671 -p 5672:5672 -p 4369:4369 -p 25672:25672 -p 15671:15671 -p 15672:15672 rabbitmq:management
~~~
> 4369,25672 Erlang发现&集群端口
> 5672 5671 AMQP端口
> 15672 web管理后台端口
> 61613 61614 STOMP协议端口
> 1883 883 MQTT协议端口

### 与SpringBoot整合
1. 引入`spring-boot-starter-amqp`
~~~xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
~~~
> 引入依赖后，RabbitAutoConfiguration就会生效
2. 配置rabbitmq相关配置信息
~~~yaml
spring:
  rabbitmq:
    host: 192.168.2.142
    port: 5672
    virtual-host: /
~~~
3. 如果想要将对象以json的形式存入队列,可以在容器中注册一个json的`MessageConverter`
~~~java
@Bean
public MessageConverter messageConverter(){
    return new Jackson2JsonMessageConverter();
}
~~~

~~~~java
@RabbitLisener(queue="xxxx")
public class RabbitConsumer{
    @RabbitHandler
    public void readMessage(Order order){}

    @RabbitHandler
    public void readMessage(Coupon coupon){}
}
~~~~

### 消息的可靠性

#### 消息丢失
- 消息发送出去，由于网络问题没有抵达MQ服务器
    - 做好容错方法，发送消息可能会网络失败，失败后要有重试机制，可记录到数据库，采用定期扫描重发的方式
        - 容错方法：try-catch
    - 做好日志记录，每个消息状态是否都被服务器收到都应该记录
    - 做好定期重发，如果消息没有发送成功，定期去数据库扫描未成功的消息进行重发
- 消息抵达Broker，Broker要将消息写入磁盘才算成功。此时Broker尚未持久化成功，出现问题
    - 消息的发送端也必须加入确认回调机制，确认成功的消息，修改数据库的消息状态
- 自动ACK的状态下，消费者收到消息还没来得及消费出现问题
    - 手动ACK，消费成功才移除这条消息，否则就noACK并且重新入队

#### 消息重复
- 消费消息成功，业务也已经处理完，但是在ack的时候出现问题，导致没有ack成功
    - 将业务逻辑设计成幂等的
    - 设计一个防重复表，每一个消息都有一个唯一的id，处理过就进行处理
    - RabbitMQ中的消息有一个redelivered字段，表示是否是重复投递过来的，可以根据这个属性来做相应的处理

#### 消息积压
- 消费者宕机
- 消费者消费能力不足
- 发送端发送流量太大
    - 上线更多的消费端
    - 上线专门的队列消费服务，将消息优先提取出来记录处理库，离线慢慢处理

# 接口幂等性解决方案

## token机制
1. 请求需要幂等的接口前客户端先获取一下token,同时服务端会将这个token进行保存，请求时将这个token带上发送给服务端
2. 服务端接收到这个token，跟自己之前存过的token进行比较，如果一样则进行业务处理，如果不一样则直接拒绝
3. 业务处理完后删除这个token
4. 后续即使客户端带着这个token发送了多次请求，因为有一次成功了且删除了token，则后面的请求都不会成功

这个过程必须保证执行过程中只有一个线程在执行，否则还是会出现重复请求的可能，即获取令牌+比较令牌+删除令牌==原子操作(可以参考redis的lua脚本)
~~~lua
if redis.call('get',KEYS[1] == ARGV[1]) then
return redis.call('del',KEYS[1])
else
return 0
end
~~~

## 各种锁机制
数据库悲观锁、数据库乐观锁、分布式锁

## 唯一约束
比如订单号唯一约束，和token机制很类似，也是先获取一个订单号，然后提交订单的时候带上订单号即可，这样创建的时候数据库的唯一约束就可以保证幂等

## 全局请求唯一id
用在有重试机制的请求上(比如Feign)，每次重试时都会使用之前的请求参数再次请求，所以就可以设置一个请求id来进行处理，只要同一个请求id处理过，
后面就不再处理
